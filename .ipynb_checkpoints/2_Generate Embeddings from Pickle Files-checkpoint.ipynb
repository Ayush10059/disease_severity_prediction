{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffba6d5f",
   "metadata": {},
   "source": [
    "# Code to Generate HAIM embeddings from HAIM-MIMIC-MM dataset\n",
    "\n",
    "### Project Info\n",
    " ->Copyright 2020 (Last Update: June 07, 2022)\n",
    " \n",
    " -> Authors: \n",
    "        Luis R Soenksen (<soenksen@mit.edu>),\n",
    "        Yu Ma (<midsumer@mit.edu>),\n",
    "        Cynthia Zeng (<czeng12@mit.edu>),\n",
    "        Ignacio Fuentes (<ifuentes@mit.edu>),\n",
    "        Leonard David Jean Boussioux (<leobix@mit.edu>),\n",
    "        Agni Orfanoudaki (<agniorf@mit.edu>),\n",
    "        Holly Mika Wiberg (<hwiberg@mit.edu>),\n",
    "        Michael Lingzhi Li (<mlli@mit.edu>),\n",
    "        Kimberly M Villalobos Carballo (<kimvc@mit.edu>),\n",
    "        Liangyuan Na (<lyna@mit.edu>),\n",
    "        Dimitris J Bertsimas (<dbertsim@mit.edu>),\n",
    "\n",
    "```\n",
    "**Licensed under the Apache License, Version 2.0**\n",
    "You may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "https://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449bfc15",
   "metadata": {},
   "source": [
    "### Requires \n",
    "```\n",
    " -> Previously generated pickle files from HAIM-MIMIC-MM Dataset\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2063bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 15:27:48.066669: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from load_mimic import *\n",
    "import gc\n",
    "\n",
    "# Full Core MIMIC-IV database path\n",
    "core_mimiciv_path = 'data/mimiciv_subset/3.1/'\n",
    "df_haim_ids = pd.read_csv(core_mimiciv_path + 'haim_mimiciv_key_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdee1132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General function that processes all data embeddings\n",
    "def process_cxr_embeddings_haim_id(haim_id, dt_patient, df_init):\n",
    "    # DEMOGRAPHICS EMBEDDINGS EXTRACTION\n",
    "    demo_embeddings = get_demographic_embeddings(dt_patient, verbose=0)\n",
    "    gc.collect() #Clear memory\n",
    "    \n",
    "    # Time Series (TSFRESH-like) CHARTEVENT & LABEVENT EMBEDDINGS EXTRACTION\n",
    "    aggregated_ts_ce_embeddings = get_ts_embeddings(dt_patient, event_type = 'chart')\n",
    "    gc.collect() #Clear memory\n",
    "    \n",
    "    aggregated_ts_le_embeddings = get_ts_embeddings(dt_patient, event_type = 'lab')\n",
    "    gc.collect() #Clear memory\n",
    "    \n",
    "    aggregated_ts_pe_embeddings = get_ts_embeddings(dt_patient, event_type = 'procedure')\n",
    "    gc.collect() #Clear memory\n",
    "    \n",
    "    # CHEST XRAY VISION EMBEDDINGS EXTRACTION\n",
    "    aggregated_densefeature_embeddings, _, aggregated_prediction_embeddings, _, _ = get_chest_xray_embeddings(dt_patient, verbose=0)\n",
    "    gc.collect() #Clear memory\n",
    "    \n",
    "    # # NOTES FROM ECGs\n",
    "    # aggregated_ecg_embeddings = get_notes_biobert_embeddings(patient, note_type = 'ecgnotes')\n",
    "    # gc.collect() #Clear memory\n",
    "    \n",
    "    # # NOTES FROM ECOCARDIOGRAMs\n",
    "    # aggregated_echo_embeddings = get_notes_biobert_embeddings(patient, note_type = 'echonotes')\n",
    "    # gc.collect() #Clear memory\n",
    "    \n",
    "    # # NOTES FROM RADIOLOGY\n",
    "    # aggregated_rad_embeddings = get_notes_biobert_embeddings(patient, note_type = 'radnotes')\n",
    "    # gc.collect() #Clear memory\n",
    "\n",
    "    # CHEST XRAY VISION SINGLE-IMAGE EMBEDDINGS EXTRACTION\n",
    "    print('getting xray')\n",
    "    img = df_imcxr[idx]\n",
    "    densefeature_embeddings, prediction_embeddings = get_single_chest_xray_embeddings(img)\n",
    "    gc.collect() #Clear memory\n",
    "\n",
    "    # Create Dataframes filteed by ordered sample number for Fusion\n",
    "    df_haim_ids_fusion = pd.DataFrame([haim_id],columns=['haim_id'])\n",
    "    df_demographics_embeddings_fusion = pd.DataFrame(demo_embeddings.reshape(1,-1), columns=['de_'+str(i) for i in range(demo_embeddings.shape[0])])\n",
    "    df_ts_ce_embeddings_fusion = pd.DataFrame(aggregated_ts_ce_embeddings.values.reshape(1,-1), columns=['ts_ce_'+str(i) for i in range(aggregated_ts_ce_embeddings.values.shape[0])])\n",
    "    df_ts_le_embeddings_fusion = pd.DataFrame(aggregated_ts_le_embeddings.values.reshape(1,-1), columns=['ts_le_'+str(i) for i in range(aggregated_ts_le_embeddings.values.shape[0])])\n",
    "    df_ts_pe_embeddings_fusion = pd.DataFrame(aggregated_ts_pe_embeddings.values.reshape(1,-1), columns=['ts_pe_'+str(i) for i in range(aggregated_ts_pe_embeddings.values.shape[0])])\n",
    "    \n",
    "    df_vision_dense_embeddings_fusion = pd.DataFrame(densefeature_embeddings.reshape(1,-1), columns=['vd_'+str(i) for i in range(densefeature_embeddings.shape[0])])\n",
    "    df_vision_predictions_embeddings_fusion = pd.DataFrame(prediction_embeddings.reshape(1,-1), columns=['vp_'+str(i) for i in range(prediction_embeddings.shape[0])])\n",
    "    df_vision_multi_dense_embeddings_fusion = pd.DataFrame(aggregated_densefeature_embeddings.reshape(1,-1), columns=['vmd_'+str(i) for i in range(aggregated_densefeature_embeddings.shape[0])])\n",
    "    df_vision_multi_predictions_embeddings_fusion = pd.DataFrame(aggregated_prediction_embeddings.reshape(1,-1), columns=['vmp_'+str(i) for i in range(aggregated_prediction_embeddings.shape[0])])\n",
    "    \n",
    "    # df_ecgnotes_embeddings_fusion = pd.DataFrame(aggregated_ecg_embeddings.reshape(1,-1), columns=['n_ecg_'+str(i) for i in range(aggregated_ecg_embeddings.shape[0])])\n",
    "    # df_echonotes_embeddings_fusion = pd.DataFrame(aggregated_echo_embeddings.reshape(1,-1), columns=['n_ech_'+str(i) for i in range(aggregated_echo_embeddings.shape[0])])\n",
    "    # df_radnotes_embeddings_fusion = pd.DataFrame(aggregated_rad_embeddings.reshape(1,-1), columns=['n_rad_'+str(i) for i in range(aggregated_rad_embeddings.shape[0])])\n",
    "    \n",
    "    # Vision targets\n",
    "    cxr_target_columns = ['split','Atelectasis','Cardiomegaly','Consolidation','Edema','Enlarged Cardiomediastinum','Fracture','Lung Lesion','Lung Opacity','No Finding','Pleural Effusion','Pleural Other','Pneumonia','Pneumothorax','Support Devices', 'PerformedProcedureStepDescription','ViewPosition']\n",
    "    df_vision_targets_fusion = df_stay_cxr.loc[idx:idx][cxr_target_columns].reset_index(drop=True)\n",
    "\n",
    "    # Embeddings FUSION\n",
    "    df_fusion = df_haim_ids_fusion\n",
    "    df_fusion = pd.concat([df_fusion, df_init], axis=1)\n",
    "    df_fusion = pd.concat([df_fusion, df_demographics_embeddings_fusion], axis=1)\n",
    "    df_fusion = pd.concat([df_fusion, df_vision_dense_embeddings_fusion], axis=1)\n",
    "    df_fusion = pd.concat([df_fusion, df_vision_predictions_embeddings_fusion], axis=1)\n",
    "    df_fusion = pd.concat([df_fusion, df_vision_multi_dense_embeddings_fusion], axis=1)\n",
    "    df_fusion = pd.concat([df_fusion, df_vision_multi_predictions_embeddings_fusion], axis=1)\n",
    "    df_fusion = pd.concat([df_fusion, df_ts_ce_embeddings_fusion], axis=1)\n",
    "    df_fusion = pd.concat([df_fusion, df_ts_le_embeddings_fusion], axis=1)\n",
    "    df_fusion = pd.concat([df_fusion, df_ts_pe_embeddings_fusion], axis=1)\n",
    "    \n",
    "    # df_fusion = pd.concat([df_fusion, df_ecgnotes_embeddings_fusion], axis=1)\n",
    "    # df_fusion = pd.concat([df_fusion, df_echonotes_embeddings_fusion], axis=1)\n",
    "    # df_fusion = pd.concat([df_fusion, df_radnotes_embeddings_fusion], axis=1)\n",
    "    \n",
    "    #Add targets\n",
    "    df_fusion = pd.concat([df_fusion, df_vision_targets_fusion], axis=1)\n",
    "    gc.collect() #Clear memory\n",
    "    \n",
    "    return df_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a129949-0011-4af2-838d-d907f00aafb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting xray\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'aggregated_ecg_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_included:\n\u001b[1;32m     39\u001b[0m     df_init \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([[img_id, img_charttime, img_deltacharttime, discharge_location, img_length_of_stay, death_status]],columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_charttime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_deltacharttime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdischarge_location\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_length_of_stay\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeath_status\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 40\u001b[0m     df_fusion \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_cxr_embeddings_haim_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhaim_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt_patient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_init\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(fname):\n\u001b[1;32m     43\u001b[0m         df_fusion\u001b[38;5;241m.\u001b[39mto_csv(fname, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[2], line 50\u001b[0m, in \u001b[0;36mprocess_cxr_embeddings_haim_id\u001b[0;34m(haim_id, dt_patient, df_init)\u001b[0m\n\u001b[1;32m     48\u001b[0m df_vision_multi_dense_embeddings_fusion \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(aggregated_densefeature_embeddings\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvmd_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(aggregated_densefeature_embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])])\n\u001b[1;32m     49\u001b[0m df_vision_multi_predictions_embeddings_fusion \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(aggregated_prediction_embeddings\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvmp_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(aggregated_prediction_embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])])\n\u001b[0;32m---> 50\u001b[0m df_ecgnotes_embeddings_fusion \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43maggregated_ecg_embeddings\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_ecg_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(aggregated_ecg_embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])])\n\u001b[1;32m     51\u001b[0m df_echonotes_embeddings_fusion \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(aggregated_echo_embeddings\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_ech_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(aggregated_echo_embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])])\n\u001b[1;32m     52\u001b[0m df_radnotes_embeddings_fusion \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(aggregated_rad_embeddings\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_rad_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(aggregated_rad_embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aggregated_ecg_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "## Let's select a single HAIM Patient from pickle files and check if it fits inclusion criteria\n",
    "haim_patient_idx = 0\n",
    "haim_id = 29098295\n",
    "\n",
    "#Load precomputed file\n",
    "filename = f\"{haim_patient_idx:08d}\" + '.pkl'\n",
    "patient = load_patient_object(core_mimiciv_path + 'pickle/' + filename)\n",
    "\n",
    "# Get information of chest x-rays conducted within this patiewnt stay\n",
    "df_cxr = patient.cxr\n",
    "df_imcxr = patient.imcxr\n",
    "admittime = patient.admissions.admittime.values[0]\n",
    "dischtime = patient.admissions.dischtime.values[0]\n",
    "df_stay_cxr = df_cxr.loc[(df_cxr['charttime'] >= admittime) & (df_cxr['charttime'] <= dischtime)]\n",
    "\n",
    "if not df_stay_cxr.empty:\n",
    "    for idx, df_stay_cxr_row in df_stay_cxr.iterrows():\n",
    "        # Get stay anchor times\n",
    "        img_charttime = df_stay_cxr_row['charttime']\n",
    "        img_deltacharttime = df_stay_cxr_row['deltacharttime']\n",
    "\n",
    "        # Get time to discharge and discharge location/status\n",
    "        img_id = df_stay_cxr_row[\"dicom_id\"]\n",
    "        img_length_of_stay = date_diff_hrs(dischtime, img_charttime)\n",
    "        discharge_location = patient.core['discharge_location'][0]\n",
    "        if discharge_location == \"DIED\": death_status = 1\n",
    "        else: death_status = 0\n",
    "            \n",
    "        # Select allowed timestamp range\n",
    "        start_hr = None\n",
    "        end_hr = img_deltacharttime\n",
    "        \n",
    "        # We need to reload it since the original object has been modified\n",
    "        patient = load_patient_object(core_mimiciv_path + 'pickle/' + filename)\n",
    "        dt_patient = get_timebound_patient_icustay(patient, start_hr , end_hr)\n",
    "        is_included = True\n",
    "\n",
    "        if is_included:\n",
    "            df_init = pd.DataFrame([[img_id, img_charttime, img_deltacharttime, discharge_location, img_length_of_stay, death_status]],columns=['img_id', 'img_charttime', 'img_deltacharttime', 'discharge_location', 'img_length_of_stay', 'death_status'])\n",
    "            df_fusion = process_cxr_embeddings_haim_id(haim_id, dt_patient, df_init)\n",
    "            \n",
    "            if os.path.isfile(fname):\n",
    "                df_fusion.to_csv(fname, mode='a', index=False, header=False)\n",
    "            else:\n",
    "                df_fusion.to_csv(fname, mode='w', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
